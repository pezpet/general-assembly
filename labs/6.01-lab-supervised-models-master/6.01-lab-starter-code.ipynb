{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Model Comparison\n",
    "\n",
    "Recall one formulation of the data science process.\n",
    "\n",
    "1. Define the problem.\n",
    "2. Gather the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model. Iterate.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. We'll define the problem and gather the data for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that they have tax benefits. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, you check out [this site](investopedia.com/ask/answers/12/401k.asp).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether someone is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "---\n",
    "### NOTE ⚠️\n",
    "\n",
    "When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import the data.\n",
    "\n",
    "##### 1. Read in the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('401ksubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9275 entries, 0 to 9274\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   e401k   9275 non-null   int64  \n",
      " 1   inc     9275 non-null   float64\n",
      " 2   marr    9275 non-null   int64  \n",
      " 3   male    9275 non-null   int64  \n",
      " 4   age     9275 non-null   int64  \n",
      " 5   fsize   9275 non-null   int64  \n",
      " 6   nettfa  9275 non-null   float64\n",
      " 7   p401k   9275 non-null   int64  \n",
      " 8   pira    9275 non-null   int64  \n",
      " 9   incsq   9275 non-null   float64\n",
      " 10  agesq   9275 non-null   int64  \n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 797.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if they were available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Occupation would probably be a good predictor of income.\n",
    "- Education level\n",
    "- Zip Code\n",
    "- Renter or Homeowner\n",
    "- Expected Retirement age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model to better predict who to target when advertising IRAs and 401(k)s. Why might this be unethical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be a discriminatory tactic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we exclude? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k     0.268178\n",
       "inc       1.000000\n",
       "marr      0.362008\n",
       "male     -0.069871\n",
       "age       0.105638\n",
       "fsize     0.110170\n",
       "nettfa    0.376586\n",
       "p401k     0.270833\n",
       "pira      0.364354\n",
       "incsq     0.940161\n",
       "agesq     0.087305\n",
       "Name: inc, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['inc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'male' and 'agesq' have correlations with income that are closest to 0. These could be good candidates for exclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs might have done this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Income squared and Age squared have been included from feature engineering. SMEs have probably found that these features improve the performance of their models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one or more variable descriptions appear to be erroneous. What's the issue and what do you think the correct value(s) should be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Income and Age were probably changed after feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all models you've learned through the date this lab was assigned that could be used to solve a regression problem. For each model type, identify whether it might be appropriate for solving this specific regression problem and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Models and their potential for solving this problem:\n",
    "- Linear/Multiple Linear Regression.\n",
    "- Ridge Regression.\n",
    "- Lasso Regression.\n",
    "- KNN Regression.\n",
    "- Decision Tree Regression.\n",
    "- Bagging.\n",
    "- Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a K-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - a boosting model\n",
    "\n",
    "    \n",
    "> As always, be sure to do a train/test split! To compare modeling techniques, use the same train-test split on each. \n",
    "\n",
    "> You may find it helpful to set up pipelines, but you are not required to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "\n",
    "models = {\n",
    "    'LinReg': LinearRegression(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'Tree': DecisionTreeRegressor(),\n",
    "    'Bagging': BaggingRegressor(),\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'Boost': AdaBoostRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Seems like including squared income here is wrong, but no indication above to exclude it\n",
    "X = data.drop(columns=['e401k', 'p401k', 'pira', 'inc', 'incsq'])\n",
    "y = data['inc']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressions(X_train, X_test, y_train, y_test, models):\n",
    "    for k, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f\"{k} R2 score: {model.score(X_test, y_test)}\")\n",
    "        try:\n",
    "            print(model.coef_)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            print(model.feature_importances_)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinReg R2 score: 0.2896129712905864\n",
      "[ 10.1143359    1.33706639  31.79434649  -3.21247748   8.36036042\n",
      " -31.88611564]\n",
      "KNN R2 score: 0.31368738655845974\n",
      "Tree R2 score: -0.18326789592736503\n",
      "[0.10284809 0.02034971 0.10595146 0.06766602 0.60312921 0.10005549]\n",
      "Bagging R2 score: 0.3045835877717117\n",
      "RandomForest R2 score: 0.3230888918946818\n",
      "[0.09970107 0.02181028 0.10344717 0.07011745 0.60158544 0.10333859]\n",
      "Boost R2 score: -0.03157212900556883\n",
      "[0.14951596 0.01173512 0.10576606 0.01495378 0.67015389 0.04787519]\n"
     ]
    }
   ],
   "source": [
    "regressions(X_train_sc, X_test_sc, y_train, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['marr', 'male', 'age', 'fsize', 'nettfa', 'agesq'], dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping is resampling our training data with replacement, so that some data/rows might show up multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged decision trees incorporate bootstraping to mitigate the high error from variance of deep decision trees, by exposing shallower trees to random bootstrapped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest is a type of bagging where a random subset of features is selected to decorrelate the otherwise high correlation trees in a bagging ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By decorrelating the decision trees in a random forest, model variance is reduced and bias is increased slightly, improving the performance of random forests over bagging in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def regressions_rmse(X_train, X_test, y_train, y_test, models):\n",
    "    for k, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f\"{k} RMSE score: {mean_squared_error(y_test, model.predict(X_test), squared=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinReg RMSE score: 20.713430555278393\n",
      "KNN RMSE score: 19.93374910374894\n",
      "Tree RMSE score: 26.509139005538216\n",
      "Bagging RMSE score: 20.55602552123894\n",
      "RandomForest RMSE score: 20.02721865877122\n",
      "Boost RMSE score: 20.69949056616224\n"
     ]
    }
   ],
   "source": [
    "regressions_rmse(X_train_sc, X_test_sc, y_train, y_test, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14.Which model performs best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model has the lowest RMSE at 19.84, so on that metric it is the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use for this problem, which one model would you pick? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would pick the KNN model because it has the lowest RMSE and the second highest R2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would run a Grid Search and tune hyperparameters:\n",
    "- 'n_neighbors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features have high correlation but could cause false positives as everyone participating in a 401k has to be eligible first, but not everyone eligible is participating.\n",
    "\n",
    "Also, commercially, if someone is already participating in a 401k then they might not be the best target for our company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all models you've learned that could be used to solve a classification problem. For each, identify whether it is appropriate for solving this specific classification problem and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression\n",
    "- KNN\n",
    "- Decision Trees\n",
    "- Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a K-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - a boosting model\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = data.drop(columns=['e401k'])\n",
    "y = data['e401k']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=13)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "models_class = {\n",
    "    'LogReg': LogisticRegression(),\n",
    "    'KNN Classifier': KNeighborsClassifier(),\n",
    "    'Tree Classifier': DecisionTreeClassifier(),\n",
    "    'Bagging Classifier': BaggingClassifier(),\n",
    "    'RandomForest Classifier': RandomForestClassifier(),\n",
    "    'Boost Classifier': AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifications(X_train, X_test, y_train, y_test, models):\n",
    "    for k, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f\"{k} Accuracy score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Accuracy score: 0.8822768434670116\n",
      "KNN Classifier Accuracy score: 0.8667529107373868\n",
      "Tree Classifier Accuracy score: 0.8059508408796895\n",
      "Bagging Classifier Accuracy score: 0.8710651142733937\n",
      "RandomForest Classifier Accuracy score: 0.877533419577404\n",
      "Boost Classifier Accuracy score: 0.8796895213454075\n"
     ]
    }
   ],
   "source": [
    "classifications(X_train_sc, X_test_sc, y_train, y_test, models_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- False positives are cases where our models predicts someone is eligible for a 401k when they are in fact not eligible.\n",
    "- False negatives are cases where our model predicts someone is NOT eligible when they are, in fact, eligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our problem statement explains that we are trying to identify potential customers, I would rather minimize false positives to save our company from contacting people who aren't even eligible for the product we are selling (401k accounts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With help from: https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba\n",
    "\n",
    "To select a model that minimizes false positives we would optimize for precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score is the harmonic mean of precision and recall, as such it balances false positives and false negatives and would be appropiate in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def classifications_f1(X_train, X_test, y_train, y_test, models):\n",
    "    for k, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            print(f\"{k} Train F1 score: {f1_score(y_train, model.predict(X_train))}\")\n",
    "            print(f\"{k} Test F1 score: {f1_score(y_test, model.predict(X_test))}\")\n",
    "        except:\n",
    "            print(f\"Could not calculate F1 for {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Train F1 score: 0.8276751181779115\n",
      "LogReg Test F1 score: 0.8233009708737864\n",
      "KNN Classifier Train F1 score: 0.8489179256839525\n",
      "KNN Classifier Test F1 score: 0.8086687306501547\n",
      "Tree Classifier Train F1 score: 1.0\n",
      "Tree Classifier Test F1 score: 0.7490389895661724\n",
      "Bagging Classifier Train F1 score: 0.9782852864095845\n",
      "Bagging Classifier Test F1 score: 0.8189762796504368\n",
      "RandomForest Classifier Train F1 score: 1.0\n",
      "RandomForest Classifier Test F1 score: 0.8196303377947737\n",
      "Boost Classifier Train F1 score: 0.8286818376985831\n",
      "Boost Classifier Test F1 score: 0.8201160541586074\n"
     ]
    }
   ],
   "source": [
    "classifications_f1(X_train_sc, X_test_sc, y_train, y_test, models_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of a great deal overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most overfit models by F1 score are:\n",
    "1. Decision Tree Classifier\n",
    "1. Random Forest Classifier\n",
    "1. Bagging Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use a LogReg classifier to find potential customers as it has the second best F1 score but can be more interpretable than others and easier to tune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would drop rows where p401k == 1 and Grid Search over hyperparameters for LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Answer the problem.\n",
    "\n",
    "##### Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "We were not able to accurately predict income unless the income squared feature was included, which isn't reasonable to include.\n",
    "\n",
    "Our models identify Net Total Financial Assets is the most important predictor for Income, followed by Age.\n",
    "\n",
    "### Classification\n",
    "Our models were able to predict Eligibility for 401k with good accuracy, though not great, and with good F1 scores, that is, with a good balance of minimizing both false positives and false negatives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
